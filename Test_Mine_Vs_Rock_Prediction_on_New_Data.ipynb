{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import inspect_checkpoint as chkp\n",
    "model_path = \"/Users/claudecoulombe/git/tensorflow_basic_tutorial/model/\"\n",
    "chkp.print_tensors_in_checkpoint_file(model_path+'model.ckpt', tensor_name='', all_tensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr columns:  61\n",
      "X.shape (8, 60)\n",
      "INFO:tensorflow:Restoring parameters from /Users/claudecoulombe/git/tensorflow_basic_tutorial/model/model.ckpt\n",
      "***************** Prediction on testing data *****************\n",
      "**************************************************************\n",
      "* 1 stands for M, (i.e. Mine) and 0 stands for R (i.e. Rock) *\n",
      "**************************************************************\n",
      "0 Original Class:  0  Predicted Values:  0\n",
      "Accuracy:  100.0%\n",
      "1 Original Class:  0  Predicted Values:  0\n",
      "Accuracy:  100.0%\n",
      "2 Original Class:  0  Predicted Values:  0\n",
      "Accuracy:  100.0%\n",
      "3 Original Class:  1  Predicted Values:  0\n",
      "Accuracy:  0.0%\n",
      "4 Original Class:  0  Predicted Values:  0\n",
      "Accuracy:  100.0%\n",
      "5 Original Class:  0  Predicted Values:  0\n",
      "Accuracy:  100.0%\n",
      "6 Original Class:  0  Predicted Values:  0\n",
      "Accuracy:  100.0%\n",
      "7 Original Class:  0  Predicted Values:  0\n",
      "Accuracy:  100.0%\n",
      "Final accuracy: 87.5%\n"
     ]
    }
   ],
   "source": [
    "# Testing model on fresh data, in fact synthesized data\n",
    "# only for the purpose of getting an idea of the generalization of the model\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "# Create new data from the dataset \"sonar.csv\" modifying the features manually \n",
    "# creating 8 «synthetized» new data and save the file as new_sonar.csv\n",
    "def read_dataset(file_name):\n",
    "    dir_path = \"/Users/claudecoulombe/git/tensorflow_basic_tutorial/\"\n",
    "    df = pd.read_csv(dir_path+file_name,delimiter=',')\n",
    "    print(\"Nbr columns: \",len(df.columns))\n",
    "    X = df[df.columns[0:60]].values\n",
    "    y = df[df.columns[60]]\n",
    "    # Encode the dependant variable\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    y = encoder.transform(y)\n",
    "    Y = one_hot_encode(y)\n",
    "    print(\"X.shape\",X.shape)\n",
    "    return (X,Y)\n",
    " \n",
    "# Define the encoder function M => 1, R => 0\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "#     n_unique_labels = len(np.unique(labels))\n",
    "    n_unique_labels = 2\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels),labels] = 1\n",
    "    return one_hot_encode\n",
    "\n",
    "# Read the dataset\n",
    "X, Y = read_dataset('new_sonar.csv')\n",
    "\n",
    "n_dim = X.shape[1] \n",
    "n_class = 2\n",
    "\n",
    "# Define the number of hidden layers an the\n",
    "# number of neurons for each layer\n",
    "n_hidden_1 = 60\n",
    "n_hidden_2 = 60\n",
    "n_hidden_3 = 60\n",
    "n_hidden_4 = 60\n",
    "\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activations\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with sigmoid activations\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.sigmoid(layer_2)\n",
    "    # Hidden layer with sigmoid activations\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    layer_3 = tf.nn.sigmoid(layer_3)\n",
    "    # Hidden layer with RELU activations\n",
    "    layer_4 = tf.add(tf.matmul(layer_3, weights['h4']), biases['b4'])\n",
    "    layer_4 = tf.nn.relu(layer_4)\n",
    "    # Output layer with linear activations\n",
    "    out_layer = tf.matmul(layer_4, weights['out']) + biases['out_b']\n",
    "    return out_layer\n",
    " \n",
    "tf.reset_default_graph() \n",
    "\n",
    "model_path = \"/Users/claudecoulombe/git/tensorflow_basic_tutorial/model/\"\n",
    "new_saver = tf.train.import_meta_graph(model_path+'model.ckpt.meta')\n",
    "\n",
    "with tf.Session() as sess:  \n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint(model_path))\n",
    "\n",
    "    # Inputs and outputs\n",
    "    x = tf.placeholder(tf.float32,[None, n_dim])\n",
    "    y_ = tf.placeholder(tf.float32,[None, n_class])\n",
    "\n",
    "    # define the weights and the biases for each layer\n",
    "    weights = {\n",
    "        'h1': sess.run(\"h1:0\"),\n",
    "        'h2': sess.run(\"h2:0\"),\n",
    "        'h3': sess.run(\"h3:0\"),\n",
    "        'h4': sess.run(\"h4:0\"),\n",
    "        'out': sess.run(\"out:0\"),\n",
    "        }\n",
    "    biases = {\n",
    "        'b1': sess.run(\"b1:0\"),\n",
    "        'b2': sess.run(\"b2:0\"),\n",
    "        'b3': sess.run(\"b3:0\"),\n",
    "        'b4': sess.run(\"b4:0\"),\n",
    "        'out_b': sess.run(\"out_b:0\"),\n",
    "        }\n",
    "\n",
    "    # Call your model defined\n",
    "   \n",
    "    print(\"***************** Prediction on testing data *****************\")\n",
    "    print(\"**************************************************************\")\n",
    "    print(\"* 1 stands for M, (i.e. Mine) and 0 stands for R (i.e. Rock) *\")\n",
    "    print(\"**************************************************************\")\n",
    "    total_success = 0\n",
    "    total_new_data_samples = 8\n",
    "    for i in range(total_new_data_samples):\n",
    "        # Call your model defined\n",
    "        prediction_run = sess.run(tf.argmax(multilayer_perceptron(x, weights, biases), 1), feed_dict={x:X[i].reshape(1,60)})\n",
    "        accuracy_run = sess.run(tf.reduce_mean(tf.cast(tf.equal(tf.argmax(multilayer_perceptron(x, weights, biases), 1), tf.argmax(y_,1)), tf.float32)), feed_dict={x:X[i].reshape(1,60), y_:Y[i].reshape(1,2)})\n",
    "        print(i,\"Original Class: \", int(sess.run(y_[i][1],feed_dict={y_:Y})), \" Predicted Values: \", prediction_run[0] )\n",
    "        print(\"Accuracy: \",str(accuracy_run*100)+\"%\")\n",
    "        if accuracy_run == 1:\n",
    "            total_success += 1 \n",
    "    print(\"Final accuracy:\",str(total_success/total_new_data_samples*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "With 87.5% , the model has shown some power of generalization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
